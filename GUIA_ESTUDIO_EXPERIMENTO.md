# ğŸ“š GuÃ­a de Estudio - Experimento de Tolerancia a Fallas en Sistemas Distribuidos

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n y Objetivos](#introducciÃ³n-y-objetivos)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Nomenclatura y Glosario](#nomenclatura-y-glosario)
4. [Funcionamiento del CÃ³digo](#funcionamiento-del-cÃ³digo)
5. [Flujo del Experimento](#flujo-del-experimento)
6. [InterpretaciÃ³n de Reportes](#interpretaciÃ³n-de-reportes)
7. [Preguntas de Estudio](#preguntas-de-estudio)
8. [Preguntas y Respuestas Frecuentes](#preguntas-y-respuestas-frecuentes)
9. [Casos de Uso y Escenarios](#casos-de-uso-y-escenarios)
10. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ IntroducciÃ³n y Objetivos

### **Â¿QuÃ© es este experimento?**

Este experimento implementa un **sistema distribuido tolerante a fallas** que simula un e-commerce con mÃºltiples servicios que deben funcionar de manera coordinada y resiliente.

### **Objetivos Principales**

1. **Demostrar tolerancia a fallas** en sistemas distribuidos
2. **Medir TTD (Time to Detect)** y **TTR (Time to Recovery)**
3. **Evaluar mecanismos de votaciÃ³n** por mayorÃ­a
4. **Probar diferentes tipos de fallos** (crash, latency, intermittent, incorrect)
5. **Validar la detecciÃ³n de outliers** en respuestas

### **TecnologÃ­as Utilizadas**

- **Flask**: Microservicios web
- **Kafka**: MensajerÃ­a asÃ­ncrona
- **PostgreSQL**: Persistencia de datos
- **Docker**: ContainerizaciÃ³n
- **Plotly**: VisualizaciÃ³n de mÃ©tricas

---

## ğŸ—ï¸ Arquitectura del Sistema

### **Diagrama de Arquitectura**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   orders-svc    â”‚    â”‚ inventory-svc-1 â”‚    â”‚ inventory-svc-2 â”‚
â”‚   (Puerto 5006) â”‚    â”‚   (Puerto 5001) â”‚    â”‚   (Puerto 5002) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â”‚                      â”‚                      â”‚
          â–¼                      â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    Kafka Cluster                       â”‚
    â”‚              (order-events, error-queue)               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â”‚                      â”‚                      â”‚
          â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   monitor-svc   â”‚    â”‚ inventory-svc-3 â”‚    â”‚   voter-svc     â”‚
â”‚   (Puerto 5004) â”‚    â”‚   (Puerto 5003) â”‚    â”‚   (Puerto 5005) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    dashboard    â”‚
â”‚   (Puerto 5007) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚
â”‚   (Puerto 5432) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Servicios y Responsabilidades**

#### **1. orders-svc (Puerto 5006)**
- **FunciÃ³n**: API sÃ­ncrona para crear/cancelar Ã³rdenes
- **Endpoints**: 
  - `POST /orders` - Crear orden
  - `DELETE /orders/<id>` - Cancelar orden
  - `GET /health` - Health check
- **ComunicaciÃ³n**: Publica eventos a Kafka

#### **2. inventory-svc (3 rÃ©plicas)**
- **FunciÃ³n**: GestiÃ³n de inventario con tolerancia a fallas
- **Puertos**: 5001, 5002, 5003
- **Endpoints**:
  - `GET /inventory` - Consultar inventario
  - `GET /health` - Health check
  - `POST /inject-failure` - Inyectar fallos
- **CaracterÃ­sticas**: 3 rÃ©plicas para votaciÃ³n por mayorÃ­a

#### **3. monitor-svc (Puerto 5004)**
- **FunciÃ³n**: Monitoreo y detecciÃ³n de fallos
- **Responsabilidades**:
  - Health checks cada 200ms
  - DetecciÃ³n de fallos (3 fallos consecutivos)
  - ActualizaciÃ³n de estado en BD
  - Consumo de cola de errores

#### **4. voter-svc (Puerto 5005)**
- **FunciÃ³n**: AgregaciÃ³n por mayorÃ­a y detecciÃ³n de outliers
- **Endpoints**:
  - `GET /inventory/voted` - Inventario por votaciÃ³n
  - `GET /voting/stats` - EstadÃ­sticas de votaciÃ³n
- **Algoritmo**: MayorÃ­a (2 de 3) + detecciÃ³n de outliers

#### **5. dashboard (Puerto 5007)**
- **FunciÃ³n**: VisualizaciÃ³n de mÃ©tricas y reportes
- **CaracterÃ­sticas**:
  - MÃ©tricas en tiempo real
  - GrÃ¡ficos interactivos
  - Reportes de experimentos
  - Auto-refresh cada 30 segundos

---

## ğŸ“– Nomenclatura y Glosario

### **TÃ©rminos TÃ©cnicos**

| TÃ©rmino | DefiniciÃ³n | Ejemplo |
|---------|------------|---------|
| **TTD** | Time to Detect - Tiempo de detecciÃ³n de fallos | 600ms |
| **TTR** | Time to Recovery - Tiempo de recuperaciÃ³n | 200ms |
| **Health Check** | VerificaciÃ³n periÃ³dica del estado de un servicio | Cada 200ms |
| **Quorum** | NÃºmero mÃ­nimo de respuestas para tomar decisiÃ³n | 2 de 3 |
| **Outlier** | Respuesta que se desvÃ­a significativamente del patrÃ³n | Latencia > 2Ïƒ |
| **Fan-out** | NÃºmero de instancias consultadas | 3 instancias |
| **Crash** | Fallo que termina completamente el proceso | `os._exit(1)` |
| **Latency** | Delay artificial en las respuestas | 1200ms |
| **Intermittent** | Fallo que ocurre con cierta probabilidad | 30% probabilidad |
| **Incorrect Response** | Respuesta con datos incorrectos | Producto inexistente |

### **MÃ©tricas del Sistema**

| MÃ©trica | DescripciÃ³n | Unidad |
|---------|-------------|--------|
| **Response Time** | Tiempo de respuesta de un endpoint | ms |
| **P95 Latency** | Percentil 95 de latencia | ms |
| **P99 Latency** | Percentil 99 de latencia | ms |
| **Request Count** | NÃºmero de requests procesados | count |
| **Success Rate** | Porcentaje de requests exitosos | % |
| **Availability** | Porcentaje de tiempo disponible | % |
| **Fan-out** | NÃºmero de instancias consultadas | count |
| **Quorum** | NÃºmero de respuestas vÃ¡lidas | count |
| **Excluded Replicas** | Instancias excluidas por outlier | count |

### **Estados de Instancias**

| Estado | DescripciÃ³n | CondiciÃ³n |
|--------|-------------|-----------|
| **ON** | Instancia funcionando correctamente | Health check OK |
| **OFF** | Instancia no disponible | 3 fallos consecutivos |
| **UNKNOWN** | Estado no determinado | Sin health checks recientes |

---

## ğŸ’» Funcionamiento del CÃ³digo

### **Estructura de Archivos**

```
experimento-test/
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ init.sql                    # Esquema de base de datos
â”œâ”€â”€ start_experiment.sh         # Script principal de control
â”œâ”€â”€ orders-svc/
â”‚   â”œâ”€â”€ app.py                  # API de Ã³rdenes
â”‚   â”œâ”€â”€ requirements.txt        # Dependencias
â”‚   â””â”€â”€ Dockerfile             # Imagen Docker
â”œâ”€â”€ inventory-svc/
â”‚   â”œâ”€â”€ app.py                  # API de inventario
â”‚   â”œâ”€â”€ requirements.txt        # Dependencias
â”‚   â””â”€â”€ Dockerfile             # Imagen Docker
â”œâ”€â”€ monitor-svc/
â”‚   â”œâ”€â”€ app.py                  # Servicio de monitoreo
â”‚   â”œâ”€â”€ requirements.txt        # Dependencias
â”‚   â””â”€â”€ Dockerfile             # Imagen Docker
â”œâ”€â”€ voter-svc/
â”‚   â”œâ”€â”€ app.py                  # Servicio de votaciÃ³n
â”‚   â”œâ”€â”€ requirements.txt        # Dependencias
â”‚   â””â”€â”€ Dockerfile             # Imagen Docker
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                  # Dashboard web
â”‚   â”œâ”€â”€ templates/              # Plantillas HTML
â”‚   â”œâ”€â”€ requirements.txt        # Dependencias
â”‚   â””â”€â”€ Dockerfile             # Imagen Docker
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ experiment_runner.py    # Ejecutor de experimentos
â”‚   â”œâ”€â”€ inject_failures.py      # InyecciÃ³n de fallos
â”‚   â”œâ”€â”€ load_test.py           # Pruebas de carga
â”‚   â”œâ”€â”€ generate_test_data.py   # GeneraciÃ³n de datos
â”‚   â””â”€â”€ cleanup_experiment.py   # Limpieza post-experimento
â””â”€â”€ jmeter/
    â”œâ”€â”€ experiment_test_plan.jmx # Plan de pruebas JMeter
    â””â”€â”€ run_test.sh             # Ejecutor JMeter
```

### **Flujo de Datos**

#### **1. CreaciÃ³n de Orden**
```python
# orders-svc/app.py
@app.route('/orders', methods=['POST'])
def create_order():
    # 1. Validar datos
    # 2. Publicar evento a Kafka
    # 3. Registrar mÃ©tricas
    # 4. Retornar respuesta
```

#### **2. Procesamiento de Inventario**
```python
# inventory-svc/app.py
def process_order_event():
    # 1. Consumir evento de Kafka
    # 2. Verificar fallos inyectados
    # 3. Procesar inventario
    # 4. Registrar mÃ©tricas
```

#### **3. Monitoreo de Salud**
```python
# monitor-svc/app.py
def health_check_worker():
    # 1. Hacer health check cada 200ms
    # 2. Contar fallos consecutivos
    # 3. Actualizar estado en BD
    # 4. Detectar recuperaciÃ³n
```

#### **4. VotaciÃ³n por MayorÃ­a**
```python
# voter-svc/app.py
def aggregate_responses():
    # 1. Consultar todas las instancias
    # 2. Detectar outliers
    # 3. Aplicar votaciÃ³n por mayorÃ­a
    # 4. Retornar resultado consensuado
```

### **InyecciÃ³n de Fallos**

#### **Tipos de Fallos Implementados**

```python
# inventory-svc/app.py
def check_failure_injection():
    if FAILURE_TYPE == 'crash':
        os._exit(1)  # Termina el proceso
        
    elif FAILURE_TYPE == 'latency':
        time.sleep(LATENCY_MS / 1000.0)  # Delay artificial
        
    elif FAILURE_TYPE == 'intermittent':
        if random.random() < FAILURE_PROBABILITY:
            raise Exception("Intermittent error")
            
    elif FAILURE_TYPE == 'incorrect_response':
        # Retorna datos incorrectos
        return incorrect_data
```

#### **Comando de InyecciÃ³n**
```bash
# Inyectar fallo crash en instancia 1
python scripts/inject_failures.py crash --instance 1

# Inyectar fallo de latencia en instancia 2
python scripts/inject_failures.py latency --instance 2 --latency_ms 1200

# Inyectar fallo intermitente en instancia 3
python scripts/inject_failures.py intermittent --instance 3 --probability 0.3

# Limpiar todos los fallos
python scripts/inject_failures.py clear --instance 1
```

---

## ğŸ”„ Flujo del Experimento

### **Fases del Experimento**

#### **Fase 1: Baseline (LÃ­nea Base)**
```python
# Medir rendimiento sin fallos
baseline_result = self.run_baseline_test()
```

**Objetivo**: Establecer mÃ©tricas de referencia
**DuraciÃ³n**: ~2 minutos
**MÃ©tricas**: Latencia, throughput, success rate

#### **Fase 2: Crash Failure**
```python
crash_result = self.inject_failure_and_measure('crash', '1')
```

**Objetivo**: Medir TTD/TTR de fallos catastrÃ³ficos
**Fallo**: `os._exit(1)` - Contenedor se detiene
**TTD Esperado**: ~600ms
**TTR**: Requiere reinicio manual

#### **Fase 3: Latency Failure**
```python
latency_result = self.inject_failure_and_measure('latency', '2', latency_ms=1200)
```

**Objetivo**: Medir impacto de latencia alta
**Fallo**: Delay artificial de 1200ms
**TTD Esperado**: ~600ms
**TTR Esperado**: ~200ms

#### **Fase 4: Intermittent Failure**
```python
intermittent_result = self.inject_failure_and_measure('intermittent', '3', probability=0.3)
```

**Objetivo**: Medir resiliencia a fallos impredecibles
**Fallo**: 30% probabilidad de error
**TTD**: Variable (depende de la frecuencia)
**TTR Esperado**: ~200ms

#### **Fase 5: Incorrect Response**
```python
incorrect_result = self.inject_failure_and_measure('incorrect', '1', product_id='PROD-001')
```

**Objetivo**: Medir detecciÃ³n de respuestas incorrectas
**Fallo**: Retorna datos incorrectos
**TTD Esperado**: ~600ms
**TTR Esperado**: ~200ms

### **MediciÃ³n de TTD/TTR**

#### **Time to Detect (TTD)**
```python
def measure_detection_time(self, instance_id):
    start_time = time.time()
    while time.time() - start_time < timeout:
        # Consultar estado en monitor-svc
        response = requests.get('http://localhost:5004/status')
        # Buscar instancia con status 'OFF'
        if instance['status'] == 'OFF':
            return time.time() - start_time
```

#### **Time to Recovery (TTR)**
```python
def measure_recovery_time(self, instance_id):
    # 1. Limpiar fallo
    subprocess.run(['python', 'scripts/inject_failures.py', 'clear', '--instance', instance_id])
    
    # 2. Medir tiempo hasta recuperaciÃ³n
    while time.time() - start_time < timeout:
        # Buscar instancia con status 'ON'
        if instance['status'] == 'ON':
            return time.time() - start_time
```

---

## ğŸ“Š InterpretaciÃ³n de Reportes

### **Estructura del Reporte JSON**

```json
{
  "experiment_info": {
    "start_time": "2025-09-06T14:20:24.722000",
    "end_time": "2025-09-06T14:35:42.156000",
    "total_duration_seconds": 917.434
  },
  "results": [
    {
      "phase": "baseline",
      "ttd_ms": null,
      "ttr_ms": null,
      "load_test_result": {
        "rps": 45.2,
        "avg_latency_ms": 89.3,
        "p95_latency_ms": 156.7,
        "p99_latency_ms": 234.1,
        "success_rate": 99.8
      }
    },
    {
      "phase": "crash",
      "ttd_ms": 623.4,
      "ttr_ms": null,
      "load_test_result": {
        "rps": 38.1,
        "avg_latency_ms": 145.2,
        "p95_latency_ms": 289.3,
        "p99_latency_ms": 456.7,
        "success_rate": 95.2
      }
    }
  ],
  "summary": {
    "total_tests": 5,
    "successful_tests": 5,
    "avg_ttd_ms": 587.2,
    "avg_ttr_ms": 198.4,
    "max_p95_ms": 289.3,
    "min_success_rate": 95.2
  }
}
```

### **InterpretaciÃ³n de MÃ©tricas**

#### **TTD (Time to Detect)**
- **Valor Ã“ptimo**: < 1000ms
- **Valor Aceptable**: < 2000ms
- **Valor CrÃ­tico**: > 5000ms

#### **TTR (Time to Recovery)**
- **Valor Ã“ptimo**: < 500ms
- **Valor Aceptable**: < 1000ms
- **Valor CrÃ­tico**: > 2000ms

#### **Success Rate**
- **Valor Ã“ptimo**: > 99%
- **Valor Aceptable**: > 95%
- **Valor CrÃ­tico**: < 90%

#### **P95 Latency**
- **Valor Ã“ptimo**: < 200ms
- **Valor Aceptable**: < 500ms
- **Valor CrÃ­tico**: > 1000ms

### **Dashboard - InterpretaciÃ³n de GrÃ¡ficos**

#### **1. GrÃ¡fico de Latencia**
- **Eje X**: Tiempo
- **Eje Y**: Latencia en ms
- **LÃ­neas**: Diferentes servicios
- **InterpretaciÃ³n**: Picos indican fallos o sobrecarga

#### **2. GrÃ¡fico de Requests**
- **Eje X**: Tiempo
- **Eje Y**: Requests por segundo
- **InterpretaciÃ³n**: CaÃ­das indican fallos de servicios

#### **3. GrÃ¡fico de Fallos**
- **Eje X**: Tiempo
- **Eje Y**: NÃºmero de fallos
- **InterpretaciÃ³n**: Picos indican detecciÃ³n de fallos

#### **4. MÃ©tricas Detalladas**
- **Tabla**: MÃ©tricas por servicio y endpoint
- **Columnas**: Servicio, Endpoint, MÃ©todo, Status, Requests, Latencia
- **InterpretaciÃ³n**: Identificar servicios problemÃ¡ticos

---

## ğŸ“š Preguntas de Estudio

### **Nivel BÃ¡sico**

1. **Â¿QuÃ© es TTD y TTR?**
   - TTD: Tiempo de detecciÃ³n de fallos
   - TTR: Tiempo de recuperaciÃ³n de fallos

2. **Â¿CuÃ¡ntas rÃ©plicas de inventory-svc hay?**
   - 3 rÃ©plicas (inventory-svc-1, inventory-svc-2, inventory-svc-3)

3. **Â¿QuÃ© puerto usa orders-svc?**
   - Puerto 5006

4. **Â¿CuÃ¡l es el umbral de fallos consecutivos para marcar una instancia como OFF?**
   - 3 fallos consecutivos

5. **Â¿Con quÃ© frecuencia hace health checks el monitor-svc?**
   - Cada 200ms

### **Nivel Intermedio**

6. **Â¿CÃ³mo funciona la votaciÃ³n por mayorÃ­a?**
   - Se consultan las 3 instancias
   - Se detectan outliers
   - Se toma la decisiÃ³n por mayorÃ­a (2 de 3)

7. **Â¿QuÃ© tipos de fallos se pueden inyectar?**
   - Crash: Termina el proceso
   - Latency: Delay artificial
   - Intermittent: Probabilidad de fallo
   - Incorrect: Respuesta incorrecta

8. **Â¿CÃ³mo se detecta un outlier?**
   - Usando desviaciÃ³n estÃ¡ndar (2Ïƒ)
   - Comparando con la media de respuestas

9. **Â¿QuÃ© hace el voter-svc?**
   - Agrega respuestas por mayorÃ­a
   - Detecta outliers
   - Proporciona inventario consensuado

10. **Â¿CÃ³mo se mide el TTD?**
    - Desde inyecciÃ³n del fallo hasta detecciÃ³n por monitor-svc

### **Nivel Avanzado**

11. **Â¿Por quÃ© se usa Kafka en este experimento?**
    - Desacoplamiento de servicios
    - MensajerÃ­a asÃ­ncrona
    - Cola de errores
    - Escalabilidad

12. **Â¿CÃ³mo se calculan los percentiles P95 y P99?**
    - P95: 95% de las respuestas estÃ¡n por debajo de este valor
    - P99: 99% de las respuestas estÃ¡n por debajo de este valor

13. **Â¿QuÃ© pasa si 2 de 3 instancias fallan?**
    - El sistema no puede tomar decisiÃ³n por mayorÃ­a
    - Se marca como fallo del sistema
    - Se requiere intervenciÃ³n manual

14. **Â¿CÃ³mo se maneja la consistencia de datos?**
    - Eventual consistency
    - VotaciÃ³n por mayorÃ­a
    - DetecciÃ³n de outliers

15. **Â¿QuÃ© mÃ©tricas se almacenan en PostgreSQL?**
    - Estado de instancias
    - MÃ©tricas de requests
    - Eventos de fallos
    - Eventos de votaciÃ³n

---

## â“ Preguntas y Respuestas Frecuentes

### **P: Â¿Por quÃ© inventory-svc-1 siempre queda en failed al final?**
**R:** Porque el experimento inyecta fallos `crash` y `incorrect` en la instancia 1, y el fallo `crash` termina completamente el contenedor. El experimento ahora incluye limpieza automÃ¡tica al final.

### **P: Â¿CÃ³mo interpreto un TTD de 600ms?**
**R:** Significa que el sistema tardÃ³ 600ms en detectar el fallo. Esto es bueno porque estÃ¡ por debajo del umbral de 1000ms.

### **P: Â¿QuÃ© significa un success rate del 95%?**
**R:** Significa que 95 de cada 100 requests fueron exitosos. Esto puede indicar fallos intermitentes o problemas de red.

### **P: Â¿Por quÃ© el dashboard muestra 0/6 servicios saludables?**
**R:** Probablemente hay un problema de conectividad entre contenedores. Verificar que todos los servicios estÃ©n corriendo con `docker ps`.

### **P: Â¿CÃ³mo sÃ© si el experimento fue exitoso?**
**R:** Revisar el reporte JSON generado. Un experimento exitoso debe tener:
- TTD < 1000ms
- TTR < 500ms (excepto crash)
- Success rate > 95%
- Todos los tests completados

### **P: Â¿QuÃ© hacer si un servicio no responde?**
**R:** 
1. Verificar con `docker ps`
2. Revisar logs con `docker logs <service-name>`
3. Reiniciar con `docker restart <service-name>`
4. Usar script de limpieza: `./start_experiment.sh cleanup`

### **P: Â¿CÃ³mo generar mÃ¡s datos para el dashboard?**
**R:** Ejecutar `python scripts/generate_test_data.py` para generar trÃ¡fico artificial.

### **P: Â¿QuÃ© significa "quorum not reached" en el voter-svc?**
**R:** Significa que no se pudo obtener mayorÃ­a (2 de 3) de respuestas vÃ¡lidas. Esto puede indicar que mÃºltiples instancias estÃ¡n fallando.

---

## ğŸ¯ Casos de Uso y Escenarios

### **Escenario 1: Fallo de una Instancia**
```
SituaciÃ³n: inventory-svc-1 falla
Resultado Esperado:
- TTD: ~600ms
- Sistema continÃºa funcionando con 2 instancias
- VotaciÃ³n por mayorÃ­a funciona
- TTR: ~200ms despuÃ©s de limpiar fallo
```

### **Escenario 2: Fallo de Dos Instancias**
```
SituaciÃ³n: inventory-svc-1 y inventory-svc-2 fallan
Resultado Esperado:
- TTD: ~600ms para ambas
- Sistema no puede tomar decisiÃ³n por mayorÃ­a
- Voter-svc reporta "quorum not reached"
- Requiere intervenciÃ³n manual
```

### **Escenario 3: Fallo Intermitente**
```
SituaciÃ³n: inventory-svc-3 con 30% probabilidad de fallo
Resultado Esperado:
- Success rate: ~70%
- TTD: Variable
- Sistema detecta outliers
- TTR: ~200ms
```

### **Escenario 4: Latencia Alta**
```
SituaciÃ³n: inventory-svc-2 con 1200ms de latencia
Resultado Esperado:
- P95 latency: ~1200ms
- TTD: ~600ms
- Sistema detecta instancia lenta
- TTR: ~200ms
```

---

## ğŸ”§ Troubleshooting

### **Problemas Comunes**

#### **1. Servicios no inician**
```bash
# Verificar estado
docker ps

# Ver logs
docker logs <service-name>

# Reiniciar todo
./start_experiment.sh restart
```

#### **2. Dashboard no muestra datos**
```bash
# Verificar conectividad
curl http://localhost:5007/health

# Verificar base de datos
docker exec -it postgres psql -U postgres -d experimento -c "SELECT COUNT(*) FROM request_metrics;"
```

#### **3. Experimentos fallan**
```bash
# Limpiar estado
./start_experiment.sh cleanup

# Verificar servicios
./start_experiment.sh status

# Reintentar experimento
./start_experiment.sh experiment
```

#### **4. Puerto en uso**
```bash
# Verificar puertos
lsof -i :5006

# Cambiar puerto en docker-compose.yml
# Reiniciar servicios
```

### **Comandos de DiagnÃ³stico**

```bash
# Estado de servicios
./start_experiment.sh status

# Logs de todos los servicios
./start_experiment.sh logs

# Limpiar y reiniciar
./start_experiment.sh cleanup

# Verificar conectividad
curl http://localhost:5006/health  # orders-svc
curl http://localhost:5001/health  # inventory-svc-1
curl http://localhost:5002/health  # inventory-svc-2
curl http://localhost:5003/health  # inventory-svc-3
curl http://localhost:5004/health  # monitor-svc
curl http://localhost:5005/health  # voter-svc
curl http://localhost:5007/health  # dashboard
```

### **VerificaciÃ³n de Base de Datos**

```sql
-- Ver estado de instancias
SELECT * FROM instance_status ORDER BY service_name, instance_id;

-- Ver mÃ©tricas de requests
SELECT service_name, endpoint, COUNT(*) as requests, AVG(latency_ms) as avg_latency
FROM request_metrics 
WHERE timestamp >= NOW() - INTERVAL '1 hour'
GROUP BY service_name, endpoint;

-- Ver fallos detectados
SELECT * FROM failure_audit 
WHERE detected_at >= NOW() - INTERVAL '1 hour'
ORDER BY detected_at DESC;

-- Ver eventos de votaciÃ³n
SELECT * FROM voting_events 
WHERE timestamp >= NOW() - INTERVAL '1 hour'
ORDER BY timestamp DESC;
```

---

## ğŸ“ˆ MÃ©tricas y KPIs

### **MÃ©tricas de Rendimiento**

| MÃ©trica | DescripciÃ³n | Valor Ã“ptimo | Valor CrÃ­tico |
|---------|-------------|--------------|---------------|
| **TTD** | Tiempo de detecciÃ³n | < 1000ms | > 5000ms |
| **TTR** | Tiempo de recuperaciÃ³n | < 500ms | > 2000ms |
| **Availability** | Disponibilidad | > 99.9% | < 95% |
| **Success Rate** | Tasa de Ã©xito | > 99% | < 90% |
| **P95 Latency** | Latencia percentil 95 | < 200ms | > 1000ms |
| **Throughput** | Requests por segundo | > 100 RPS | < 10 RPS |

### **MÃ©tricas de Tolerancia a Fallas**

| MÃ©trica | DescripciÃ³n | Valor Ã“ptimo |
|---------|-------------|--------------|
| **Quorum Success** | Ã‰xito en votaciÃ³n | > 95% |
| **Outlier Detection** | DetecciÃ³n de outliers | > 90% |
| **Failure Coverage** | Cobertura de tipos de fallo | 100% |
| **Recovery Success** | Ã‰xito en recuperaciÃ³n | > 95% |

---

## ğŸ“ GuÃ­a de PresentaciÃ³n

### **Estructura Recomendada para Sustentar**

#### **1. IntroducciÃ³n (5 minutos)**
- Objetivo del experimento
- Arquitectura del sistema
- TecnologÃ­as utilizadas

#### **2. DemostraciÃ³n en Vivo (10 minutos)**
- Mostrar dashboard funcionando
- Ejecutar un experimento pequeÃ±o
- Explicar mÃ©tricas en tiempo real

#### **3. AnÃ¡lisis de Resultados (10 minutos)**
- Interpretar reportes generados
- Explicar TTD/TTR
- Mostrar grÃ¡ficos y mÃ©tricas

#### **4. Preguntas y Respuestas (5 minutos)**
- Responder preguntas tÃ©cnicas
- Explicar decisiones de diseÃ±o
- Discutir mejoras posibles

### **Puntos Clave a Destacar**

1. **Tolerancia a Fallas**: Sistema continÃºa funcionando con fallos
2. **DetecciÃ³n RÃ¡pida**: TTD < 1000ms
3. **RecuperaciÃ³n RÃ¡pida**: TTR < 500ms
4. **VotaciÃ³n por MayorÃ­a**: Consenso entre rÃ©plicas
5. **DetecciÃ³n de Outliers**: IdentificaciÃ³n de respuestas anÃ³malas
6. **Monitoreo en Tiempo Real**: Dashboard con mÃ©tricas actualizadas

### **PreparaciÃ³n para Preguntas**

- **Conocer los nÃºmeros**: TTD, TTR, percentiles, success rates
- **Entender la arquitectura**: Flujo de datos, comunicaciÃ³n entre servicios
- **Saber interpretar mÃ©tricas**: QuÃ© significa cada valor
- **Conocer limitaciones**: QuÃ© pasa con 2 de 3 fallos
- **Tener ejemplos**: Casos de uso reales

---

## ğŸ“š Recursos Adicionales

### **DocumentaciÃ³n TÃ©cnica**
- [Flask Documentation](https://flask.palletsprojects.com/)
- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Docker Documentation](https://docs.docker.com/)

### **Conceptos de Sistemas Distribuidos**
- Tolerancia a Fallas
- Consenso y VotaciÃ³n
- Monitoreo y Observabilidad
- Patrones de Microservicios

### **Herramientas de Monitoreo**
- Prometheus + Grafana
- ELK Stack (Elasticsearch, Logstash, Kibana)
- Jaeger (Tracing distribuido)
- Zipkin (Tracing distribuido)

---

## âœ… Checklist de PreparaciÃ³n

### **Antes de la PresentaciÃ³n**

- [ ] Todos los servicios funcionando
- [ ] Dashboard accesible
- [ ] Datos de ejemplo generados
- [ ] Reportes de experimentos disponibles
- [ ] Comandos de demostraciÃ³n preparados
- [ ] Preguntas frecuentes revisadas
- [ ] Backup de datos importante

### **Durante la PresentaciÃ³n**

- [ ] Mostrar dashboard en tiempo real
- [ ] Ejecutar experimento en vivo
- [ ] Explicar mÃ©tricas paso a paso
- [ ] Responder preguntas con ejemplos
- [ ] Demostrar troubleshooting si es necesario

### **DespuÃ©s de la PresentaciÃ³n**

- [ ] Limpiar estado del sistema
- [ ] Documentar preguntas no respondidas
- [ ] Recopilar feedback
- [ ] Planificar mejoras

---

**Â¡Buena suerte con tu presentaciÃ³n! ğŸš€**

*Esta guÃ­a cubre todos los aspectos necesarios para sustentar el experimento de manera exitosa. Recuerda practicar la demostraciÃ³n y estar preparado para preguntas tÃ©cnicas detalladas.*